{"cells":[{"cell_type":"markdown","metadata":{"id":"9MkmhBp2ZyIC"},"source":["# How to begin:\n","\n","The sign language detection software requires uploading a set of hand signs to match to. The \"matching set\" folder should include all required information, simply:\n","\n","1. Download the matching set folder\n","2. Go to the right had side of this page and click on the folder icon\n","3. At the top of the Files menu, there is an upload button\n","4. navigate **inside** of the match folder, and upload all files\n","5. run all of the \"SVD & other setup\" cells\n","6. choose between a photo or live feed, and run associated cells\n","7. use your **right** hand, and enjoy!\n","\n","At the bottom of the page is some debugging information that may help understand the program, so try those out too!"]},{"cell_type":"markdown","metadata":{"id":"BwNDTYCZSleW"},"source":["# SVD & other setup"]},{"cell_type":"markdown","metadata":{"id":"DCZWyigFVCJc"},"source":["## Install libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxbHBsF-8Y_l"},"outputs":[],"source":["!pip install -q mediapipe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OMjuVQiDYJKF"},"outputs":[],"source":["!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"]},{"cell_type":"markdown","metadata":{"id":"6kEGYf7IisoD"},"source":["### convert to matrix\n","\n","in format [x_coords, y_coords, z_coords]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qEhytbcDg3J4"},"outputs":[],"source":["#just print x, y, z matricies\n","\n","from mediapipe import solutions\n","from mediapipe.framework.formats import landmark_pb2\n","import numpy as np\n","\n","MARGIN = 10  # pixels\n","\n","def coord_matrix(rgb_image, detection_result):\n","  hand_landmarks_list = detection_result.hand_landmarks\n","\n","  # Loop through the detected hands to visualize.\n","  for idx in range(len(hand_landmarks_list)):\n","    hand_landmarks = hand_landmarks_list[idx]\n","\n","    #nate's addition\n","    x_coords = [landmark.x for landmark in hand_landmarks]\n","    y_coords = [landmark.y for landmark in hand_landmarks]\n","    z_coords = [landmark.z for landmark in hand_landmarks]\n","\n","    return [x_coords, y_coords, z_coords]"]},{"cell_type":"markdown","metadata":{"id":"pJG0axunkd_f"},"source":["## Single Value Decomposition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6A8gcHyN3v6x"},"outputs":[],"source":["#applying above \"convert to matrix\" to a function\n","\n","from mediapipe import solutions\n","from mediapipe.framework.formats import landmark_pb2\n","import numpy as np\n","import mediapipe as mp\n","from mediapipe.tasks import python\n","from mediapipe.tasks.python import vision\n","\n","MARGIN = 10  # pixels\n","\n","def coord_matrix(photo_name):\n","  base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n","  options = vision.HandLandmarkerOptions(base_options=base_options,\n","                                        num_hands=2)\n","  detector = vision.HandLandmarker.create_from_options(options)\n","  image = mp.Image.create_from_file(photo_name)\n","  detection_result = detector.detect(image)\n","  rgb_image = image.numpy_view()\n","\n","\n","\n","  hand_landmarks_list = detection_result.hand_landmarks\n","\n","  # Loop through the detected hands to visualize.\n","  for idx in range(len(hand_landmarks_list)):\n","    hand_landmarks = hand_landmarks_list[idx]\n","    x_coords = [landmark.x for landmark in hand_landmarks]\n","    y_coords = [landmark.y for landmark in hand_landmarks]\n","    z_coords = [landmark.z for landmark in hand_landmarks]\n","\n","    return np.array([x_coords, y_coords, z_coords])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zpq0EN6DX48y","executionInfo":{"status":"ok","timestamp":1723268740809,"user_tz":300,"elapsed":8766,"user":{"displayName":"Nathaniel Grenke","userId":"12660288536386531653"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"30574082-a918-412c-b380-7d68dbdac1bb"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n","  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"]}],"source":["# make the set of photos to match to\n","import cv2\n","import zipfile\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","\n","gestures = [coord_matrix(\"SignA.jpg\")]\n","# load the images dataset\n","with zipfile.ZipFile(\"match.zip\") as facezip:\n","    for filename in facezip.namelist():\n","        if filename == \"SignA.jpg\":\n","            continue # skip SignA, covered in gestures intialization\n","        b = coord_matrix(filename)\n","        b = np.expand_dims(b, axis=0)\n","        gestures = np.append(gestures, b, axis=0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ho4XcRZ5yc2B"},"outputs":[],"source":["# making set to match to, called gestures\n","# A is index (1, 0, 0)\n","# G is index (7, 0, 0)\n","row_vect = gestures[[0],:,:] # Take out the 0th gesture\n","\n","col_vect = row_vect.reshape((63,1))\n","A = col_vect\n","for i in range(1, 72): #change to number of signs ----------------------\n","  row_vect = gestures[[i],:,:] # Take out the ith gesture\n","  col_vect = row_vect.reshape((63,1))\n","  A = np.hstack((A, col_vect))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"07aywKMmz86Y","executionInfo":{"status":"ok","timestamp":1723268753864,"user_tz":300,"elapsed":170,"user":{"displayName":"Nathaniel Grenke","userId":"12660288536386531653"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"15cb21df-e502-441e-b739-2a90243c3937"},"outputs":[{"output_type":"stream","name":"stdout","text":["(63, 72)\n"]}],"source":["\n","A_bar = A - (1 / A.shape[1]) * (A @ ( np.ones((A.shape[1], 1)) @ np.ones((1, A.shape[1])) )) # centered A\n","U, sigma, V_T = np.linalg.svd(A_bar)\n","\n","k = 63 #the first k colomns of U ------------------------\n","B_hat = U[:, :k]\n","sigmat  = np.diag(sigma)[:k, :k]\n","Vk = V_T.T[:, :k]\n","W_hat = sigmat @ Vk.T\n","print(np.shape(W_hat))"]},{"cell_type":"markdown","metadata":{"id":"XgX2Oe89Usdb"},"source":["## photo match function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GIy35hdVNObn"},"outputs":[],"source":["#photo match as a function\n","\n","def nearest_neighbor(w_i):\n","  dist_list = np.ones((W_hat.shape[1]))\n","  for i in range(W_hat.shape[1]):\n","    dist_list[i] = np.linalg.norm(W_hat[:, i:i+1] - w_i)\n","  return np.argmin(dist_list)\n","\n","def guess_image(jpg_name): #jpg_name is string\n","  abcArr = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\"]\n","  test_img1 = coord_matrix(jpg_name)\n","  z_1 = np.reshape(test_img1, (63, 1))  #vectorize test_img1\n","  z_1_bar = z_1 - (1 / A.shape[1]) * A @ np.ones((A.shape[1], 1))  # center z_1\n","  w_1 = np.transpose(B_hat) @ z_1_bar  # caculate according to z_1_bar and B_hat\n","  ind_1 = nearest_neighbor(w_1) % 24  # find the index of the nearest neighbour according to w_1 and W_hat\n","  print(abcArr[ind_1]) # A = 0, B = 1, ... , G = 6"]},{"cell_type":"markdown","metadata":{"id":"geJYcf2hYI9O"},"source":["# Use of software\n","\n","two options:\n","1. take photo, one capture at a time\n","2. live feed"]},{"cell_type":"markdown","source":["## take photo"],"metadata":{"id":"hJXsu29t3TXx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kxmTkCyiXoFh"},"outputs":[],"source":["#part of take photo, below\n","from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","  data = eval_js('takePhoto({})'.format(quality))\n","  binary = b64decode(data.split(',')[1])\n","  with open(filename, 'wb') as f:\n","    f.write(binary)\n","  return filename"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":857},"executionInfo":{"elapsed":5870,"status":"error","timestamp":1723270460909,"user":{"displayName":"Nathaniel Grenke","userId":"12660288536386531653"},"user_tz":300},"id":"6d3vi9625Pfz","outputId":"23146603-50f4-49a9-b21d-4d9f2daa3e1e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-9c68fbbaac75>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#takes photos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saved to {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-27-214490095aa4>\u001b[0m in \u001b[0;36mtake_photo\u001b[0;34m(filename, quality)\u001b[0m\n\u001b[1;32m     37\u001b[0m     ''')\n\u001b[1;32m     38\u001b[0m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'takePhoto({})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m   \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#takes photos\n","from IPython.display import Image\n","filename = take_photo()\n","print('Saved to {}'.format(filename))\n","\n","# Show the image which was just taken.\n","guess_image(\"photo.jpg\")\n","display(Image(filename))"]},{"cell_type":"markdown","source":["#live feed\n","\n","Due to google's attempts to prevent any live video capabilities, the live feed has some odd running behavior, but it still works!\n","\n","Simply run the live feed, then *stop* the cell. This will start the program taking photos and interpreting results. Then to actually stop the program, a new option will apear below the run button (a little box with an arrow). click that and clear output."],"metadata":{"id":"MZmbwn3y1PYT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bo8pKufXM_C3","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"fca806e5-a894-47f4-bdae-aba24ab0c15e","executionInfo":{"status":"error","timestamp":1723270468033,"user_tz":300,"elapsed":1838,"user":{"displayName":"Nathaniel Grenke","userId":"12660288536386531653"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","      async function takePhotoContinuous(interval, quality) {\n","        const div = document.createElement('div');\n","        const video = document.createElement('video');\n","        video.style.display = 'block';\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","        document.body.appendChild(div);\n","        div.appendChild(video);\n","        video.srcObject = stream;\n","        await video.play();\n","\n","        // Resize the output to fit the video element.\n","        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","        while (true) {\n","          const canvas = document.createElement('canvas');\n","          canvas.width = video.videoWidth;\n","          canvas.height = video.videoHeight;\n","          canvas.getContext('2d').drawImage(video, 0, 0);\n","          const data = canvas.toDataURL('image/jpeg', quality);\n","          // Return data to Python kernel\n","          google.colab.kernel.invokeFunction('notebook.take_photo', [data], {});\n","          // Print message\n","          google.colab.kernel.invokeFunction('notebook.print_message', ['Captured photo'], {});\n","          // Wait for interval\n","          await new Promise(resolve => setTimeout(resolve, interval * 1000));\n","        }\n","      }\n","    "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-063558d51264>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Start capturing photos continuously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mtake_photo_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-29-063558d51264>\u001b[0m in \u001b[0;36mtake_photo_continuous\u001b[0;34m(interval, quality)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Call the JavaScript function to start capturing photos continuously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'takePhotoContinuous({}, {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Define a function to receive the captured photo data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"stream","name":"stdout","text":["Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","L\n","Captured photo\n","Photo captured and saved as photo.jpg\n","L\n","Captured photo\n","Photo captured and saved as photo.jpg\n","L\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","A\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","Captured photo\n","Photo captured and saved as photo.jpg\n","L\n","Captured photo\n","Photo captured and saved as photo.jpg\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","P\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","G\n","Captured photo\n","Photo captured and saved as photo.jpg\n","N\n","Captured photo\n","Photo captured and saved as photo.jpg\n","G\n","Captured photo\n","Photo captured and saved as photo.jpg\n","G\n","Captured photo\n"]}],"source":["#live feed, with SVD processing\n","from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","from google.colab import output\n","\n","def take_photo_continuous(interval=1, quality=0.8):\n","    js = Javascript('''\n","      async function takePhotoContinuous(interval, quality) {\n","        const div = document.createElement('div');\n","        const video = document.createElement('video');\n","        video.style.display = 'block';\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","        document.body.appendChild(div);\n","        div.appendChild(video);\n","        video.srcObject = stream;\n","        await video.play();\n","\n","        // Resize the output to fit the video element.\n","        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","        while (true) {\n","          const canvas = document.createElement('canvas');\n","          canvas.width = video.videoWidth;\n","          canvas.height = video.videoHeight;\n","          canvas.getContext('2d').drawImage(video, 0, 0);\n","          const data = canvas.toDataURL('image/jpeg', quality);\n","          // Return data to Python kernel\n","          google.colab.kernel.invokeFunction('notebook.take_photo', [data], {});\n","          // Print message\n","          google.colab.kernel.invokeFunction('notebook.print_message', ['Captured photo'], {});\n","          // Wait for interval\n","          await new Promise(resolve => setTimeout(resolve, interval * 1000));\n","        }\n","      }\n","    ''')\n","    display(js)\n","    # Call the JavaScript function to start capturing photos continuously\n","    eval_js('takePhotoContinuous({}, {})'.format(interval, quality))\n","\n","# Define a function to receive the captured photo data\n","def handle_photo(data):\n","    binary = b64decode(data.split(',')[1])\n","    with open('photo.jpg', 'wb') as f:\n","        f.write(binary)\n","    print('Photo captured and saved as photo.jpg')\n","    guess_image(\"photo.jpg\") # ACTUAL GUESSING FUNCTION HERE  -----------\n","\n","\n","# Define a function to print a message\n","def print_message(message):\n","    print(message)\n","\n","# Register the Python functions to be called from JavaScript\n","output.register_callback('notebook.take_photo', handle_photo)\n","output.register_callback('notebook.print_message', print_message)\n","\n","# Start capturing photos continuously\n","take_photo_continuous(interval=1, quality=0.8)\n"]},{"cell_type":"markdown","metadata":{"id":"OGEJMz8EjFFw"},"source":["# Testing\n"]},{"cell_type":"markdown","metadata":{"id":"RmjBQcnQSXDA"},"source":["### image with landmark points"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Htb1CvXp-Tq5"},"outputs":[],"source":["#function to print image with anchor points\n","\n","from mediapipe import solutions\n","from mediapipe.framework.formats import landmark_pb2\n","import numpy as np\n","\n","MARGIN = 10  # pixels\n","FONT_SIZE = 1\n","FONT_THICKNESS = 1\n","HANDEDNESS_TEXT_COLOR = (88, 205, 54) # vibrant green\n","\n","def draw_landmarks_on_image(rgb_image, detection_result):\n","  hand_landmarks_list = detection_result.hand_landmarks\n","  handedness_list = detection_result.handedness\n","  annotated_image = np.copy(rgb_image)\n","\n","  # Loop through the detected hands to visualize.\n","  for idx in range(len(hand_landmarks_list)):\n","    hand_landmarks = hand_landmarks_list[idx]\n","    handedness = handedness_list[idx]\n","\n","    # Draw the hand landmarks.\n","    hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n","    print(hand_landmarks_proto)\n","    hand_landmarks_proto.landmark.extend([\n","      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n","    ])\n","    solutions.drawing_utils.draw_landmarks(\n","      annotated_image,\n","      hand_landmarks_proto,\n","      solutions.hands.HAND_CONNECTIONS,\n","      solutions.drawing_styles.get_default_hand_landmarks_style(),\n","      solutions.drawing_styles.get_default_hand_connections_style())\n","\n","    # Get the top left corner of the detected hand's bounding box.\n","    height, width, _ = annotated_image.shape\n","    x_coordinates = [landmark.x for landmark in hand_landmarks]\n","    y_coordinates = [landmark.y for landmark in hand_landmarks]\n","    text_x = int(min(x_coordinates) * width)\n","    text_y = int(min(y_coordinates) * height) - MARGIN\n","\n","    #nate's addition\n","    x_coords = [landmark.x for landmark in hand_landmarks]\n","    y_coords = [landmark.y for landmark in hand_landmarks]\n","    z_coords = [landmark.z for landmark in hand_landmarks]\n","    print(len(x_coords))\n","    print(len(y_coords))\n","    print(len(z_coords))\n","\n","    # Draw handedness (left or right hand) on the image.\n","    cv2.putText(annotated_image, f\"{handedness[0].category_name}\",\n","                (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n","                FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n","\n","  return annotated_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XSS68pp9aoDK"},"outputs":[],"source":["# STEP 1: Import the necessary modules.\n","import mediapipe as mp\n","from mediapipe.tasks import python\n","from mediapipe.tasks.python import vision\n","\n","# STEP 2: Create an HandLandmarker object.\n","base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n","options = vision.HandLandmarkerOptions(base_options=base_options,\n","                                       num_hands=2)\n","detector = vision.HandLandmarker.create_from_options(options)\n","\n","# STEP 3: Load the input image.\n","image = mp.Image.create_from_file(\"photo.jpg\")\n","\n","# STEP 4: Detect hand landmarks from the input image.\n","detection_result = detector.detect(image)\n","\n","# STEP 5: Process the classification result. In this case, visualize it.\n","annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n","cv2_imshow(cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n","guess_image(\"photo.jpg\")\n"]}],"metadata":{"colab":{"collapsed_sections":["OGEJMz8EjFFw"],"provenance":[{"file_id":"1r4gwLqGKxLQbgXpR3RzjtoK3eExTzpbK","timestamp":1713813866984},{"file_id":"1SiuCPtoSEvoIQ4ytqW-LLfXsO71VMHlf","timestamp":1712802114392},{"file_id":"https://github.com/googlesamples/mediapipe/blob/main/examples/hand_landmarker/python/hand_landmarker.ipynb","timestamp":1712800133681}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}